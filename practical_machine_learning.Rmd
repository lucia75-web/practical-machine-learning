---
title: "Practical Machine Learning Project"
output:
  word_document: default
  html_document: default
  pdf_document: default
---
### Overview
The goal of your project is to predict the manner in which they did the exercise.
This is the "classe" variable in the training set. You may use any of the other variables to predict with. 
A report describing has been created to show how to built the model, how to use cross validation. 


### Load the Library
Check for missing dependencies and load necessary R packages
```{r, echo = TRUE}
setwd("~/Coursera/practical-machine-learning")
library(knitr)
library(caret)
```
###  Read the test and  training dataset 
```{r, echo = TRUE}
training <- read.csv("./pml-training.csv")
testing <- read.csv("./pml-testing.csv")

dim(training)
dim(testing)
```
###  Prepare the data
The data are prepared for the analysis: the not applicable data and not a number data 
are removed from the data read form the *.csv file
```{r, echo = TRUE}
# remove variables that are almost always NA

training <- training[, colSums(is.na(training)) == 0] 

classe <- training$classe
trainRemove <- grepl("^X|timestamp|window", names(training))
training <- training[, !trainRemove]
training <- training[, sapply(training, is.numeric)]
training$classe <- classe

```

### Split the data in two subset
Split the training data in two dataset, a 70% is used for training and a 30% is used to 
verified the predicted model. 
```{r, cache = T}
datasplitted <- createDataPartition(training$classe, p=0.70, list=FALSE)
mytrainData <- training[datasplitted, ]
mytestData <- training[-datasplitted, ]
```

###  Data Modeling
Fit the predictive model.
Two model are estimated to find the best model, the randoms forest and the conditional Inference Tree
```{r, echo = TRUE}
modelTree <- train(classe ~ ., data=mytrainData, method="ctree", trControl=trainControl())
print(modelTree)

controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=mytrainData, method="rf", trControl=controlRf, ntree=250)
print(modelRf)

```
Analyzing the two models we can see that the randoms forest is the model with a better accuracy.

###Evaluation of the model on the training data
Models is evalued on the 30% of the training data not used for fitting.
```{r, echo = TRUE}
predictTree <- predict(modelTree, mytestData)
accuracyTree <- postResample(predictTree, as.factor(mytestData$classe))
accuracyTree

predictRf <- predict(modelRf, mytestData)
accuracyRf <- postResample(predictRf,  as.factor(mytestData$classe))
accuracyRf
```
The same accuracy is confirmed on the data training used for the test.

###  Predicting for Test Data Set
Results on the testing data, take in account that the modelRf is the best model
```{r, cache = T}
resultRf <- predict(modelRf, testing)
print(resultRf)
```